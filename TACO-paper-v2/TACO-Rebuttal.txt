We thank our reviewers (R1-R4). We appreciate the positive feedback and the
critical comments on our paper. Below we answer the various points arose by the
reviewers.

R1:
We agree the big missing part was a discussion on the generality of our
approach and the applicability of the code transformations to other
computational domains (or, perhaps, their integration within a general-purpose
compilers). We added therefore a complete new section (Section 6) that explains
these aspects in details. We believe this addition was necessary to let readers
understand how to transfer our work to a different domain or compiler (or, at
least, to let them gain something from our experience of designing/developing 
the code transformations and COFFEE).

We also addressed all of the other useful comments (1-8) provided:
1) The goal is to develop a class of optimizations for an infinite variety of 
local assembly code. In that paragraph we say "(...) makes it hard to determine 
a single or specific sequence of transformations that is successfully 
applicable to all problems (...)", which implies that different finite element 
problems may require different code optimizations due to the inherent diversity 
in mathematical expressions and loop trip counts (this aspect is reiterated 
throughout the paper). Therefore, a compiler-based approach, in which the input 
and some parameters are analyzed to decide how to optimally transform the code 
is needed to get as close as possible to peak performance. Another possibility 
would be a library-based approach, although it would be quite pointless since 
we can directly generate the most suitable code for each problem.
2) The variation in loop trip counts impacts loop transformation. If the loop 
is relatively large, for example, vector-register tiling is likely to be useful 
to minimize register spilling; if it's small, then full or partial unrolling is 
an option. Understanding the border between "small" and "large" is challenging.  
The cost model helps in this direction. We tried to clarify the point you make 
in various sections in the paper: the sentence at page 6 has been re-written to 
anticipate the fact that "different loop sizes require different 
transformations". Then we discuss on the importance and the impact of loop 
unrolling in Section 4 (there is a complete new paragraph about that).  
Finally, in Section 5.2.5, we demonstrate our claim as discussing the impact of 
vector-register tiling (paragraphs 4, 5 and 6 of that section) in our 
benchmarks.
3) Clarified in the paper by adding/re-writing a few sentences. The short 
answer is: yes.
4) Explained in the paper.
5) We agree. We removed the code listing and expanded Figure 4.
6) Explained in the paper.
7) This was already explained by the sentence "Other optimization levels 
performed, in general, slightly worse."
8) We believe each of those tables can be represented by 6 different charts (1 
for each <Architecture, Equation> examined>). We have not done that for lack of 
space (the submission for acceptance is limited to 25 pages) but we can easily 
do that, if really needed, in the final version of the paper (which can be 
30-page long)

******************************************************************************

R2:
Two main critiques are moved to our paper.

a) We do not think that "the techniques of the paper are mostly interesting to 
a subset of the people in the intersection of code optimization and finite 
element methods". However, we do agree that the paper was missing an in-depth 
explanation about how to re-adapt/re-use our transformations in other contexts, 
perhaps other DSLs or even general-purpose compilers. Also, we believe that our 
experience of developing COFFEE and integrating it in a real-world framework 
based on a domain-specific language can be of inspiration for other research 
and/or engineering work. We therefore introduced a complete new section, 
Section 6, about the generality of our approach and the applicability of the 
code transformations to other computational domains. We hope you can read this 
section carefully, because it represents novel contribution of the paper and 
aims to answer exactly the concern you pointed out.

b) The results of the paper are *really* applicable to other kernels beyond 
those analyzed and presented. First of all, we want to emphasize a number of 
aspects. What is important to clarify is that kernels are not "mere small 
pieces of code" but rather numerical routines that evaluate an integral in each 
element of the discretized equation domain, produced by means of a real (used 
by many scientists around the world) domain-specific language (and compiler).  
Therefore, there is an infinite variety of kernels that can be generated in 
Firedrake, and their code structure (loop sizes and mathematical expression) 
depends on the partial differential equation that is being solved. This is 
explained and re-iterated in the paper. Also, when we vary the polynomial order 
of the method or the domain discretization (triangles, tetrahedrons, prisms) we 
actually change the code generation by increasing loops and arrays sizes and by 
making mathematical expressions more articulated (this happens, for example, 
when moving from 2D domains to 3D ones). So we are already testing many 
different code variants. This is carefully explained in Section 5.2.1. Now, 
premised that, back to your very point, which is "applicability and 
effectiveness of our transformations in other local assembly kernels". Our 
answer is twofold:

- Section 5.2.1 explains in-depth the motivations behind the choice of the 
  three problems (helmholtz, Diffusion, Burgers), explaining (in short) that 
"(...) distinct problems, possibly arising in completely different fields, may 
employ (subsets of) the same differential operators of our benchmarks, which 
implies similarities and redundant patterns in the generated code.  
Consequently, the proposed code transformations have a domain of applicability 
that goes far beyond that of the three analyzed equations. (...)". Then we 
re-inforce this later on in the section and in the paper. Other kernels arising 
from completely different equations will still have the same high-level 
structure of the kernels we examined (e.g. same memory access pattern, same 
ranges of loop sizes, same problems concerning the presence of loop-invariant 
code and register pressure) so there is no reason for which our code 
optimizations would not be effective. The critical issue in our research was to 
understand what transformations our local assembly kernels required, and how to 
instantiate parametric transformations (vector-register tiling, loop 
interchange, expression splitting) optimally in each possible problem (this led 
to the development of the cost model).

- In Section 5.3 we provide a full-application study in which we analyze a 
  different equation (Linear Elasticity), which brings the total number of 
studied equations to 4 (Helmholtz, Diffusion, Burgers, Elasticity)
Adding more kernels to the performance evaluation section would make the paper 
only more chaotic: we selected these three problems to highlight all pros and 
cons of our code transformations. This is the reason for which we comment on 
the code transformations and their interplay in specific sub-sections, 
referring to, describing, and carefully analyzing all of the provided plots. 

Other concerns:
- It is actually not true that we do not consider other optimization 
  strategies: 1) a comparison with using linear algebra libriries (the 
comparison uses hand-crafted kernels) and 2) a comparison with the FEniCS Form 
Compiler's built-in optimization system (which is the result of a cited paper) 
are provided.
- We agree it is useful to report speed ups and execution times for the whole finite element 
  calculation. We have added a new section (Section 5.3) about a 
full-application study, showing exactly these values.
- At some points in the paper (introduction and related work) we cite studies 
  concerning local assembly and GPUs. These works however deeply differ 
from ours for a number of reasons, including the fact that they are outside of 
the context of automated code generation, they are limited to only very 
low-order methods (typically only polynomial order 1), and they do not try to 
optimize for cross-loop arithmetic intensity as we do. The goal in these works 
is rather to understand how to effectively parallelize the local assembly code (so as 
to have multiple threads executing a single kernel, as opposed to our execution 
model in which we assume a single thread per kernel) in specific equations (not 
in a possibly infinite range as we do). A critical issue when executing local 
assembly kernels on GPUs is represented by memory requirements. We give here 
two examples, although more problems could be discussed. First, the transfer of 
the mesh from host to GPU may be a notable obstacle: if too big, the mesh
will not fit the available GPU memory, and distributed execution, which is 
marginally supported in available finite element frameworks, would be required. 
Secondly, optimizations like generalized loop-invariant code motion further increase 
the memory requirements due to the introduction of temporary arrays. This may 
actually lead to poor per-thread shared memory and registers allocation. These 
aspects suggest that the problem of executing generic, automatically-generated local 
assembly kernels on GPUs require a separate, in-depth study. However, in the 
new Section 6, we provide some intuitions of how we could re-adapt COFFEE's 
transformations for execution on GPUs.
