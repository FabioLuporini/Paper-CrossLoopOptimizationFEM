We thank our reviewers (R1-R4). We appreciate the positive feedback on our 
paper. We agree and will correct the presentation issues concerning jargon, 
applications, motivations, relationship with other (polyhedral) tools.

1.Applications (R2, R3, R4)
The three benchmark kernels chosen are completely real examples and comprise the 
core operators in some of the most frequently encountered finite element 
problems. The Helmholtz and Diffusion kernels are unsimplified examples of the 
operators which occur for diffusion and viscosity in fluids, and for imposing 
pressure in compressible fluids. The Burgers kernel is a typical example of a 
first order hyperbolic conservation law, which occurs in real applications 
whenever a quantity is transported by a fluid (in our case, the quantity 
transported is the momentum itself). These kernels were chosen because they are 
exponents of a much larger class of problems (i.e. problems using same/similar 
differential operators), for which the same optimisations would be expected to 
be equally effective. Our claim of being "real-world examples" is indeed 
correct, and we want to carefully explain this in the paper.
The fact that the resulting local assembly kernels are small but computationally 
intensive is a consequence of the mathematical structure of the finite element 
method, not a restriction or a simplificative assumption we made. Thus, this is 
truly realistic.
Note that the succesful use of domain-specific abstractions drastically 
simplified the development of finite element methods for our tests (see the 
reference to the UFL code in the paper); however, the code generation in 
Firedrake is a complex piece of software involving thousands lines of code.

2.Motivations (R2, R3)
Computational cost is a critical limitation in finite element simulations. To 
provide one particular example we are particularly concerned about, it has been 
well established that mesh resolution is critical in the accuracy of numerical 
weather forecasts. However, operational forecast centres have a strict time 
limit in which to produce a forecast (60 minutes in the case of the UK Met 
Office). Hence, producing simulation systems which fully exploit the available 
computational resource has a direct scientific payoff in higher 
resolution, and therefore more accurate, forecasts. Consequently, aggressive 
optimization of local assembly, which typically represents a large fraction of 
the overall finite element method's execution time, directly impacts large-scale 
simulations running on supercomputers.

3.Relationship with other tools (R1, R3, R4)
Polyhedral and vendor compilers do not (practically: can not) apply the 
transformations automated in COFFEE because of their domain-specific and/or 
non-affine nature. For example, as explained in the paper, the generalized 
loop-invariant code motion exploits the mathematical property that the size of 
the loops may be identical to minimize pre-computation of hoisted terms. 
Vector-register tiling is tied to the peculiar memory access pattern 
characterizing our kernels: to the best of our knowledge, no register tiling 
technique computing outer-products using in-register shuffling has ever been 
automated in a tool. Padding, as questioned in R4, is safe in our kernels, but 
in general is not; in addition, it is mostly profitable for very small arrays: 
so, again, no compilers adopt it.  The split transformation, as pointed out by 
R1, is based on the associativity of sums, which breaks standard loop fissioning 
optimizations reasoning on memory access pattern and iteration space.

4.Technical aspects (R1, R2, R4)
- R1 (splittng): we plan to clarify the distinction between classic loop 
  fission and code splitting.
- R2 (overhead): The grow in code and memory footprint is always limited. There 
  is no particular manual loop unrolling that makes the code exceeding the 
instruction cache. The use of temporaries for loop-invariant code motion is 
minimized by avoiding redundant precomputation of same sub-expressions; 
our profiling experiments show that, even when high-order polynomials are 
employed, the use of temporaries never outreaches the L1 cache (i.e.  
loop-invariant code motion is always profitable).
- R4 (padding): As explained earlier, padding is always safe: values computed in 
  the padded regions of the element matrix are simply discared once returned 
from the assembly routine.
- R4 (loop fusion): In Section 3B we explain that we want to vectorize lines 
  13-14, and the simplest way of triggering compiler's auto-vectorization is to 
put those statements in an innermost loop, given a tree of loops.
- R4 (registers): More registers would make the optimization problem even more 
  interesting: that is exactly why we have tested the transformations on the 
intel phi, where we have 32 logical registers instead of 16 as in the sandy 
bridge. 

5.Jargon (R1, R2, R3, R4)
We will definitely simplify the unclear descriptions related to the finite 
element methid and give more intuition about its general structure, avoiding the 
use of technical terms that make the paper difficult to read.
